{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f585f862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV   #module which is used for hyperparameter tuning.\n",
    "from sklearn import metrics    # provides various metrics to evaluate the performance of the model.\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier   #KerasClassifier is a class from keras.wrappers.scikit_learn module which provides a wrapper for Keras models to be used in sklearn.\n",
    "from tensorflow.keras.models import Sequential #Sequential is a class from tensorflow.keras.models module which is used to initialize a sequential neural network.\n",
    "from tensorflow.keras.layers import Dense, Activation   #Dense and Activation are classes from tensorflow.keras.layers module which are used to add dense and activation layers to the neural network.\n",
    "from tensorflow.keras.callbacks import EarlyStopping   #EarlyStopping is a class from tensorflow.keras.callbacks module which is used to stop training the model early based on a certain condition.\n",
    "from keras.utils.vis_utils import plot_model    #used to plot the architecture of the neural network.\n",
    "#classes from sklearn library which provide different machine learning algorithms for classification.\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "#from sklearn.externals.six import StringIO  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as pyplot\n",
    "from sklearn.metrics import roc_auc_score, roc_curve  #used to compute the ROC AUC score and plot the ROC curve for binary classification problems.\n",
    "from sklearn.metrics import confusion_matrix    \n",
    "from warnings import simplefilter  #simplefilter is a method from warnings library which is used to ignore certain warning messages during the execution of the code.\n",
    "import time   #time is a module from Python's standard library which is used to measure the execution time of the code.\n",
    "start = time.time()\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0af52a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with two dataset splitted\n",
    "dftrain = pd.read_csv(\"train70_reduced.csv\") \n",
    "dftest = pd.read_csv(\"test30_reduced.csv\")\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "seed = 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bf820b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "class_names = dftrain.target.unique()\n",
    "dftrain=dftrain.astype('category')\n",
    "cat_columns = dftrain.select_dtypes(['category']).columns\n",
    "dftrain[cat_columns] = dftrain[cat_columns].apply(lambda x: x.cat.codes)\n",
    "x_columns = dftrain.columns.drop('target')\n",
    "x_train = dftrain[x_columns].values\n",
    "y_train = dftrain['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb3e2d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to generate train and test datasets\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "class_names = dftest.target.unique()\n",
    "dftest=dftest.astype('category')\n",
    "cat_columns = dftest.select_dtypes(['category']).columns\n",
    "dftest[cat_columns] = dftest[cat_columns].apply(lambda x: x.cat.codes)\n",
    "x_columns = dftest.columns.drop('target')\n",
    "x_test = dftest[x_columns].values\n",
    "y_test = dftest['target']\n",
    "\n",
    "\n",
    "print(\"Ready to generate train and test datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07714fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LGBM Classifier\n",
      "Training time: 3.735215902328491\n",
      "Test time: 0.577794075012207\n"
     ]
    }
   ],
   "source": [
    "#LGBM Technique\n",
    "print(\"Starting LGBM Classifier\")\n",
    "model = LGBMClassifier(colsample_bytree=0.9361488190481075,\n",
    "               learning_rate=0.1297772691304215, max_bin=1023,\n",
    "               min_child_samples=2, n_estimators=130, num_leaves=8,\n",
    "               reg_alpha=0.004577823970660193, reg_lambda=0.18619134161599754,\n",
    "               verbose=-1)\n",
    "model.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "diff=end-start\n",
    "print(\"Training time: \" + str(diff))\n",
    "starttest = time.time()\n",
    "y_pred_mlp = model.predict(x_test)\n",
    "endtest =time.time()\n",
    "difftest = endtest-starttest\n",
    "print(\"Test time: \" + str(difftest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d178072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Classifier, accuracy: 0.9035753852351697 F1 score:0.9006564251543165\n",
      "[[ 3429   587     0     7   328     0]\n",
      " [  210 35594     0  3250    23     0]\n",
      " [    2     4    10    98    70     0]\n",
      " [    0  3171     0 46468     0     0]\n",
      " [ 1050   311     5   458  1454     0]\n",
      " [    0     0     0     0     0  2761]]\n"
     ]
    }
   ],
   "source": [
    "print(\"LGBM Classifier, accuracy: \" + str(metrics.accuracy_score(y_test, y_pred_mlp)) + \" F1 score:\" + str(metrics.f1_score(y_test, y_pred_mlp,average='weighted')))\n",
    "matrixml = confusion_matrix(y_test,y_pred_mlp)\n",
    "print(matrixml)\n",
    "\n",
    "p1=metrics.accuracy_score(y_test, y_pred_mlp)\n",
    "\n",
    "f1=metrics.f1_score(y_test, y_pred_mlp,average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae874cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Random Forest\n",
      "Training time: 4.605611085891724\n",
      "Test time: 0.016937971115112305\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "print(\"Starting Random Forest\")\n",
    "classifier = RandomForestClassifier(criterion='entropy', max_features=0.38,\n",
    "                       max_leaf_nodes=80, n_estimators=4, n_jobs=-1,\n",
    "                       random_state=7)\n",
    "classifier.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "diff=end-start\n",
    "print(\"Training time: \" + str(diff))\n",
    "starttest = time.time()\n",
    "y_pred_random = classifier.predict(x_test)\n",
    "endtest =time.time()\n",
    "difftest = endtest-starttest\n",
    "print(\"Test time: \" + str(difftest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d06e7157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest, accuracy: 0.9050055393292376 F1 score:0.9025424804242836\n",
      "[[ 3558   536     0     9   248     0]\n",
      " [  225 35554     0  3263    35     0]\n",
      " [    1     4    88    90     1     0]\n",
      " [    0  3171     0 46468     0     0]\n",
      " [ 1087   281    24   457  1429     0]\n",
      " [    0     0     0     0     0  2761]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest, accuracy: \" + str(metrics.accuracy_score(y_test, y_pred_random)) + \" F1 score:\" + str(metrics.f1_score(y_test, y_pred_random,average='weighted')))\n",
    "matrixrf = confusion_matrix(y_test,y_pred_random)\n",
    "print(matrixrf)\n",
    "\n",
    "p2=metrics.accuracy_score(y_test, y_pred_random)\n",
    "\n",
    "f2=metrics.f1_score(y_test, y_pred_random,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cae4ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Convolutional Neural Network\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-13 10:09:04.330919: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 - 4s - loss: 9.9388 - accuracy: 0.7284 - val_loss: 0.5573 - val_accuracy: 0.8107 - 4s/epoch - 15ms/step\n",
      "Epoch 2/200\n",
      "232/232 - 3s - loss: 0.5454 - accuracy: 0.8233 - val_loss: 0.4243 - val_accuracy: 0.8262 - 3s/epoch - 14ms/step\n",
      "Epoch 3/200\n",
      "232/232 - 3s - loss: 0.4441 - accuracy: 0.8659 - val_loss: 0.4012 - val_accuracy: 0.8388 - 3s/epoch - 13ms/step\n",
      "Epoch 4/200\n",
      "232/232 - 3s - loss: 0.4082 - accuracy: 0.8796 - val_loss: 0.3756 - val_accuracy: 0.8435 - 3s/epoch - 15ms/step\n",
      "Epoch 5/200\n",
      "232/232 - 3s - loss: 0.3661 - accuracy: 0.8889 - val_loss: 0.3707 - val_accuracy: 0.8434 - 3s/epoch - 14ms/step\n",
      "Epoch 6/200\n",
      "232/232 - 3s - loss: 0.3563 - accuracy: 0.8934 - val_loss: 0.3599 - val_accuracy: 0.8793 - 3s/epoch - 14ms/step\n",
      "Epoch 7/200\n",
      "232/232 - 3s - loss: 0.3354 - accuracy: 0.8956 - val_loss: 0.3478 - val_accuracy: 0.8813 - 3s/epoch - 14ms/step\n",
      "Epoch 8/200\n",
      "232/232 - 3s - loss: 0.3114 - accuracy: 0.9007 - val_loss: 0.3519 - val_accuracy: 0.8855 - 3s/epoch - 14ms/step\n",
      "Epoch 9/200\n",
      "232/232 - 3s - loss: 0.3134 - accuracy: 0.9011 - val_loss: 0.3442 - val_accuracy: 0.8835 - 3s/epoch - 14ms/step\n",
      "Epoch 10/200\n",
      "232/232 - 3s - loss: 0.3042 - accuracy: 0.9021 - val_loss: 0.3559 - val_accuracy: 0.8563 - 3s/epoch - 14ms/step\n",
      "Epoch 11/200\n",
      "232/232 - 3s - loss: 0.2916 - accuracy: 0.9042 - val_loss: 0.3643 - val_accuracy: 0.8516 - 3s/epoch - 15ms/step\n",
      "Epoch 12/200\n",
      "232/232 - 3s - loss: 0.2792 - accuracy: 0.9075 - val_loss: 0.3683 - val_accuracy: 0.8580 - 3s/epoch - 14ms/step\n",
      "Epoch 13/200\n",
      "232/232 - 3s - loss: 0.2756 - accuracy: 0.9083 - val_loss: 0.3879 - val_accuracy: 0.8554 - 3s/epoch - 12ms/step\n",
      "Epoch 14/200\n",
      "232/232 - 3s - loss: 0.2698 - accuracy: 0.9100 - val_loss: 0.3822 - val_accuracy: 0.8575 - 3s/epoch - 11ms/step\n",
      "Epoch 14: early stopping\n",
      "Training time: 49.47242712974548\n",
      "3103/3103 [==============================] - 1s 442us/step\n",
      "Test time: 1.7850580215454102\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 31, 1, 32)         128       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 1, 32)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 1, 64)         6208      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 1, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 384)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               49280     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                1548      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,164\n",
      "Trainable params: 57,164\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Convolutional Neural Network\n",
    "# Reshape the data into a 4D tensor for CNN\n",
    "x_train_cnn = x_train.reshape(x_train.shape[0], x_train.shape[1], 1, 1)\n",
    "x_test_cnn = x_test.reshape(x_test.shape[0], x_test.shape[1], 1, 1)\n",
    "\n",
    "print(\"Starting Convolutional Neural Network\")\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 1), activation='relu', input_shape=(x_train.shape[1], 1, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "history = model.fit(x_train_cnn, y_train, validation_data=(x_test_cnn, y_test), callbacks=[monitor], verbose=2, epochs=200, batch_size=1000) \n",
    "end = time.time()\n",
    "diff = end - start\n",
    "print(\"Training time: \" + str(diff))\n",
    "\n",
    "starttest = time.time()\n",
    "y_pred_cnn = model.predict(x_test_cnn)\n",
    "y_pred_cnn = np.argmax(y_pred_cnn, axis=1)\n",
    "endtest = time.time()\n",
    "difftest = endtest - starttest\n",
    "print(\"Test time: \" + str(difftest))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4fa063c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolutional Neural network, accuracy: 0.8575284520092658 F1 score:0.8558522815630242\n",
      "[[ 3562   529     6   235    19     0]\n",
      " [ 3662 31267     0  4145     3     0]\n",
      " [    2     3    62   117     0     0]\n",
      " [   49  2633     0 46957     0     0]\n",
      " [ 1699   406     9   617   535    12]\n",
      " [    0     0     0     0     0  2761]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Convolutional Neural network, accuracy: \" + str(metrics.accuracy_score(y_test, y_pred_cnn)) + \" F1 score:\" + str(metrics.f1_score(y_test, y_pred_cnn,average='weighted')))\n",
    "matrixcnn = confusion_matrix(y_test,y_pred_cnn)\n",
    "print(matrixcnn)\n",
    "\n",
    "\n",
    "p3=metrics.accuracy_score(y_test, y_pred_cnn)\n",
    "\n",
    "f3=metrics.f1_score(y_test, y_pred_cnn,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b47dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Gradient boost\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7911           54.85s\n",
      "         2           0.6706           56.07s\n",
      "         3           0.5791           54.08s\n",
      "         4           0.5090           52.96s\n",
      "         5           0.4536           52.17s\n",
      "         6           0.4097           50.94s\n"
     ]
    }
   ],
   "source": [
    "#Gradient boost\n",
    "print(\"Starting Gradient boost\")\n",
    "model = GradientBoostingClassifier(n_estimators=50, max_depth=5, random_state=seed, verbose=2)\n",
    "model.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "diff=end-start\n",
    "print(\"Training time: \" + str(diff))\n",
    "starttest = time.time()\n",
    "y_pred_gradient = model.predict(x_test)\n",
    "endtest =time.time()\n",
    "difftest = endtest-starttest\n",
    "print(\"Test time: \" + str(difftest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8c559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GradientBoost, accuracy: \" + str(metrics.accuracy_score(y_test, y_pred_gradient)) + \" F1 score:\" + str(metrics.f1_score(y_test, y_pred_gradient,average='weighted')))\n",
    "matrixgb = confusion_matrix(y_test,y_pred_gradient)\n",
    "print(matrixgb)\n",
    "\n",
    "\n",
    "p4=metrics.accuracy_score(y_test, y_pred_gradient)\n",
    "\n",
    "f4=metrics.f1_score(y_test, y_pred_gradient,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b066279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "print(\"Starting Naive Bayes\")\n",
    "# Feature selection\n",
    "selector = SelectKBest(score_func=f_classif, k=5)\n",
    "x_train_sel = selector.fit_transform(x_train, y_train)\n",
    "x_test_sel = selector.transform(x_test)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train_sel, y_train)\n",
    "end = time.time()\n",
    "diff=end-start\n",
    "print(\"Training time: \" + str(diff))\n",
    "\n",
    "starttest = time.time()\n",
    "y_pred_nb = gnb.predict(x_test_sel)\n",
    "endtest =time.time()\n",
    "difftest = endtest-starttest\n",
    "print(\"Test time: \" + str(difftest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ef4b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Naive Bayes, accuracy: \" + str(metrics.accuracy_score(y_test, y_pred_nb)) + \" F1 score:\" + str(metrics.f1_score(y_test, y_pred_nb,average='weighted')))\n",
    "matrixnv = confusion_matrix(y_test,y_pred_nb)\n",
    "print(matrixnv)\n",
    "\n",
    "p5=metrics.accuracy_score(y_test, y_pred_nb)\n",
    "\n",
    "f5=metrics.f1_score(y_test, y_pred_nb,average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af3aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3322e8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [p1, p2, p3, p4, p5]\n",
    "list2 = [\"LGBM\", \"Random Forest\", \"CNN\", \"Gradient Boost\", \"Naive Bayes\"]\n",
    "list3 = [f1, f2, f3, f4, f5]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "width = 0.4\n",
    "\n",
    "plt.bar([i - width/2 for i in range(len(list1))], list1, width=width, label='Accuracy')\n",
    "plt.bar([i + width/2 for i in range(len(list3))], list3, width=width, color='orange', label='F1 Score')\n",
    "\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Comparison of Algorithm Scores\")\n",
    "plt.xticks(range(len(list2)), list2)\n",
    "\n",
    "for i, v in enumerate(list1):\n",
    "    plt.text(i - 0.35, v + 0.01, str(round(v, 3)))\n",
    "for i, v in enumerate(list3):\n",
    "    plt.text(i + 0.05, v + 0.01, str(round(v, 3)))\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92acc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9fc92b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9189fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
